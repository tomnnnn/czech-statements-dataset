#!/bin/bash
#PBS -l select=1:ncpus=1:mem=12gb:ngpus=1:gpu_mem=40gb:scratch_local=10gb
#PBS -j oe

export TMPDIR=$SCRATCHDIR
export HF_HOME=$DATA/.hf # set Hugging Face cache directory
export CUDA_VISIBLE_DEVICES=0
export OUTPUT_DIR=$DATA/$OUTPUT
# export PYTORCH_CUDA_ALLOC_CONF="max_memory_reserved_gb:40"

echo "Job started on $(hostname) at $(date) with index $PBS_ARRAY_INDEX"

mkdir -p "$OUTPUT_DIR" # prepare output folder

cd "$SCRATCHDIR" || { echo "Failed to change to scratch directory"; exit 1; }

# Load required modules
module add mambaforge
module add cuda

# Activate conda environment
if ! mamba activate "$DATA/.mamba/env"; then
	echo "Failed to activate mamba environment"
	exit 1
fi

# Copy scripts and data to scratch space
cp "$DATA/$PROMPT_PATH" prompt.yaml
cp -r "$DATA/src" .

# Run baseline script
PYTHONPATH=src python -m src.evaluate_dataset			\
	$EXPLANATION						\
	-o $OUTPUT_DIR						\
	-i $PBS_ARRAY_INDEX					\
	-m $MAX_INDEX						\
	-b $BATCH_SIZE						\
	-t $SAMPLE_PORTION					\
	--example-count $EXAMPLE_COUNT				\
	--allowed-labels $ALLOWED_LABELS			\
	--dataset-path $DATA/$DATASET_PATH			\
	--evidence-source $EVIDENCE_SOURCE			\
	--prompt-config prompt.yaml				\
	--model-api $MODEL_API					\
	$MODEL_FILE						\
	$MODEL

# Finalize
clean_scratch
echo "Job completed successfully at $(date)"

